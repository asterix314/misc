#import "template.typ": template, menu

#show: template

= 运维监控

在“运维中心”可以监控各任务运行的情况、浏览任务报错日志、启动、重跑、停止任务等。此外，还可以监控整个“集成开发平台”产品运行节点的健康状况。

== 实时集成任务

进入#menu([运维中心],[实时集成任务])页面，在任务运维标签页的列表中找到相关任务，然后在右侧的操作栏中点击#menu([数据统计])，即可查看历史同步的数据量和同步速度（@fig:实时集成数据统计）等健康参数。

#figure(
  rect(image("img/实时集成数据统计.png", width: 80%)),
  caption: [实时集成数据统计],
) <实时集成数据统计>

*对实时集成任务，应重点关注异常日志*（#menu([运维中心],[实时集成任务], [异常日志])）。如果报错是暂时性的（如@fig:实时集成日志），则可以不必理会，因为CDC机制会在后续的同步成功时弥补以前的缺失。

#figure(
  rect(image("img/实时集成日志.png", width: 80%)),
  caption: [实时集成日志],
) <实时集成日志>

当源端业务系统的数据或数据结构发生重大变化、或数据由前期试用阶段转为正式投产等特殊情况时，可能想要清空数据平台中已经实时同步的数据，并重新同步全量数据。进入#menu([运维中心],[实时集成任务])页面，在任务运维标签页的列表中找到相关任务，然后在右侧的操作栏中点击#menu([重跑])（@fig:重跑实时集成任务）。该操作可将该任务内同步数据的目的表进行清空，然后重新从来源表同步全量数据到目的表中。

#figure(
  rect(image("img/重跑实时集成任务.png", width: 80%)),
  caption: [重跑实时集成任务],
) <重跑实时集成任务>

== 离线集成和数据加工任务

*对离线集成和数据加工任务，应关注最近一个时段的失败任务*。用筛选条件查询（如@fig:数据加工失败任务查询），再查看失败任务的日志。

#figure(
  rect(image("img/数据加工失败任务查询.png", width: 80%)),
  caption: [数据加工失败任务查询],
) <数据加工失败任务查询>

注意：如果任务频率较高（如每分钟都运行），则系统会积累下大量的运行记录和日志，造成后续查询缓慢甚至无法查询。目前的解决方案是只查最近时段（如最近一小时）且状态为“失败”的任务。

== 集群监控

#figure(
  rect(image("img/集群监控.png", width: 80%)),
  caption: [集群监控],
) <集群监控>

集群监控的页面如@fig:集群监控 所示。 需要注意的是，无论是调度集群还是工作集群，#highlight[监控的对象都是产品功能的运行节点，而不是业务数据的存储节点]。也就是说，@fig:集群监控 中那几百G的“磁盘可用空间”不是 doris 数据存储的磁盘空间。这些节点执行调度任务、转发任务，以及 python、shell 这些任务也都会在上面运行。占用磁盘空间的主要是系统日志文件等。

当任务监控界面出现报错或无法查询等异常时，不妨浏览一下集群监控界面，看有没有异常（高CPU使用率或内存占用、磁盘可用量枯竭等），或许可以为定位问题提供一些提示。


